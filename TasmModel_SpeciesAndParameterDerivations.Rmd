---
title: "Setting up species, their parameters and resource parameters for the SE Tasmanian model"
author: "Asta Audzijonyte et al."
date: "2019-Nov-7"
output: html_document
---
### clear memory

```{r}

rm(list=ls())

```

### Load libraries

```{r warning=FALSE, message=FALSE, warning=FALSE, echo=F}
#list.files()

#devtools::install_github("james-thorson/FishLife")
list.of.packages <- c("tidyverse", "dplyr", "ggplot2", "ggmap", "vegan", "reshape2", "cowplot", "factoextra", "data.table", "googleway", "ggrepel", "ggspatial", 
    #"libwgeom", 
    "sf", 
    "rnaturalearth", 
    "rnaturalearthdata",
    "rgeos")

new.packages<- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only = TRUE)

```

### Load datafiles

```{r warning=FALSE, message=FALSE, eval=T, echo = F} 
#underwater surveys for Bassian ecoregion
load(file="../inputs/rlsbas_mar2019.RData") 

rls_bas$dayID <- paste(rls_bas$day,rls_bas$month, rls_bas$year, rls_bas$SiteCode, rls_bas$Depth, sep = "") #unique date - site code identfier

traits <- read.csv(file = "../inputs/SpeciesTraits.csv") #collection of Tasmanian species traits by Rick
thermal <- read.csv(file = "../inputs/ThermalOptima.csv") #Ricks thermal database
FBdata <- read.csv(file = "../inputs/FBlifehistory.csv")
diet = read.csv (file = "../inputs/dietpred.csv")
ComNames = read.csv(file = "../inputs/SpeciesCommonNames.csv")
Lmax = read.csv(file = "../inputs/CorrectLmax.csv")
lw <- read.csv(file = "../inputs/SpeciesLW.csv")

```

### Tasmanian samples: select species 

```{r warning=FALSE, message=FALSE, eval=T, echo = F} 
ComNames <- ComNames[,c(1:2)]

# ## This is a list of locations in 4 long term monitored areas
# This was intially used for model development, but later we switched too all surveys south of northern Tasmanian coast
# MariaLocs = c("Maria Island Reserve", "Maria Island Vincinity", "Maria External")
# TinderLocs = c("Tinderbox External", "Tinderbox Reserve")
# NineLocs = c("Ninepin Internal", "Ninepin External")
# BichLocs = c("Bicheno Internal", "Bicheno External")
# 
# #Set this to the wanted area
# LocationsWanted = c(MariaLocs, TinderLocs, NineLocs, BichLocs)

## cutoff for the year periods
#yearEarly = 2000 ## 1990s
#yearMid = 2010 ## 2000s

## Get only the data for longterm locations, method 1 and for the 1990s
#fish.early.LT.M1 <- rls_bas %>% filter (Location %in% LocationsWanted) %>% filter (year < 2000) %>% filter (Method == 1)
## Or try all surveys from E, W and S coast of Tamania (N coast has different spp) and 1990s
fish.early.LT.M1 <- rls_bas %>% filter (SiteLat < -40.8) %>% filter (year < 2000) %>% filter (Method == 1)
## Or use all years
#fish.early.LT.M1 <- rls_bas %>% filter (SiteLat < -40.8) %>% filter (Method == 1)

#how many surveys are there? 
survno <- length(unique(fish.early.LT.M1$SurveyID)) #1965

# Select only species that occur in more than x% of surveys with a given biomass and abudance 
BasianCommonFish <- fish.early.LT.M1 %>%
  filter (GENUS != "NA") %>% #Ignore species for which only family name is known
    group_by (TAXONOMIC_NAME, SurveyID) %>% ## group by species and survey to summarise species/survey data
       summarise (abundSur = sum(Abundance), biomSur = sum(BioMass, na.rm=TRUE)) %>% #add all observations per survey to get abundance and biomass per survey
      group_by (TAXONOMIC_NAME) %>%
        summarise(freq_surv = n_distinct(SurveyID)/survno, abun_surv = sum(abundSur)/survno, bio_surv = sum(biomSur)/survno) %>%
  filter (freq_surv > 0.025) %>% #the cutoff of 2.5% reduces the list of spp from 103 to 32
            filter (bio_surv > 25) %>% arrange (desc(bio_surv))

BasianCommonFish$commonName <- ComNames$COMMON_NAME[match(BasianCommonFish$TAXONOMIC_NAME,ComNames$TAXONOMIC_NAME)]
BasianCommonFish$Lmax <- Lmax$LmaxCorrect[match(BasianCommonFish$TAXONOMIC_NAME,Lmax$TAXONOMIC_NAME)]

knitr::kable(BasianCommonFish, digits = 2)

#excluded rarer species or those that are not keystone spp (after consultation with experts)

excspp <- c("Girella zebra","Cheilodactylus nigripes", "Urolophus cruciatus","Pseudolabrus mortonii","Diodon nicthemerus" ,"Neoodax balteatus", "Caesioperca lepidoptera")

#Model species
ModelSpecies <- BasianCommonFish %>% filter((!TAXONOMIC_NAME %in% excspp))

knitr::kable(ModelSpecies, digits = 2)
#save(ModelSpecies, file = "../inputs/ModelSpeciesSummary.RData")

```

### How much biomass & abund model fish make up?

```{r warning=FALSE, message=FALSE, eval=T, echo = F}
#load(file="../inputs/rlsbas_mar2019.RData") 
#load(file = "../inputs/ModelSpeciesSummary.RData")

#Mean survey abundance and biomass of fish and sharks 
SurvBioAb <- rls_bas %>% 
  filter (SiteLat < -40.8) %>%
  filter (CLASS == "Actinopterygii" | CLASS == "Elasmobranchii") %>% 
  filter (Method == "1") %>% 
  group_by (SurveyID) %>% 
  summarise (bio = sum(BioMass, na.rm = T), abun = sum(Abundance), year = first(year))

SurvBioAb16 <- rls_bas %>% 
  filter (SiteLat < -40.8) %>%
  filter (TAXONOMIC_NAME %in% ModelSpecies$TAXONOMIC_NAME) %>% 
  filter (Method == "1") %>% 
  group_by (SurveyID) %>% 
  summarise (bio16 = sum(BioMass, na.rm = T), abun16 = sum(Abundance))

#combine mean abundacne a
SurvTotal <- full_join(SurvBioAb, SurvBioAb16, by = "SurveyID")

#If none of the species were present the biomas and abund will be shown as NA. I need to replace them as 0
 SurvTotal$bio16[which(is.na(SurvTotal$bio16) == TRUE)] <- 0
 SurvTotal$abun16[which(is.na(SurvTotal$abun16) == TRUE)] <- 0
 
# Now get the proportion of biomass and abundane that the 16 species make up
SurvTotal$bioRatio = SurvTotal$bio16 / SurvTotal$bio
SurvTotal$abunRatio = SurvTotal$abun16 / SurvTotal$abun

#get median proportion of per survey fish and shark biomass and abundance made up by these 16 species in years < 2000
median(SurvTotal$bioRatio[which(SurvTotal$year < 2000)], na.rm = T) #0.96
median(SurvTotal$abunRatio[which(SurvTotal$year < 2000)], na.rm = T) #0.92

#and across years 
median(SurvTotal$bioRatio, na.rm = T) #0.96
median(SurvTotal$abunRatio, na.rm = T) #0.91

```

### Prepare data of abundance/bio per survey

```{r warning=FALSE, message=FALSE, eval=T, echo = F, eval = F}
# load(file="../inputs/rlsbas_mar2019.RData")
# load(file = "../inputs/ModelSpeciesSummary.RData")

#if doing only for the 1990s use this line: 
#fish.early.LT.M1 <- rls_bas %>% filter (SiteLat < -40.8) %>% filter (year < 2000) %>% filter (Method == 1)

fish.early.LT.M1 <- rls_bas %>% filter (SiteLat < -40.8) %>% filter (Method == 1)
length(unique(fish.early.LT.M1$SurveyID)) #1965 ##6683 in total
surveys <- unique(fish.early.LT.M1$SurveyID)

#SurveyYear <- fish.early.LT.M1 %>% group_by(SurveyID) %>% summarise (year = first(year), spp = n_distinct(TAXONOMIC_NAME))

SurveyYear <- fish.early.LT.M1 %>% group_by(SurveyID) %>% summarise (year = first(year))

## First sum biomass and number of each model species in each survey
ModelSppAbund <- rls_bas %>% 
  filter (SiteLat < -40.8) %>%
  #filter (year < 2000) %>%  #if doing only for the 1990s use this line: 
  filter (TAXONOMIC_NAME %in% ModelSpecies$TAXONOMIC_NAME) %>% 
  filter (Method == "1") %>% 
  group_by (TAXONOMIC_NAME, SurveyID) %>% 
  summarise (bio16 = sum(BioMass, na.rm = T), abun16 = sum(Abundance))

#Now we have  biomases and abundances of all model species per each survey. But if a species was not present in the survey it will not be recorded, and we do not know for how many surveys a given species was absent from. So from this data we can't estimate mean per survey abundance or sd of abundance. We want to create a file with all surveys for each species and 0 if a species was not present

temp1 <- rep(surveys, each = length(ModelSpecies$TAXONOMIC_NAME)) ## vector of surveys by species
temp2 <- rep(ModelSpecies$TAXONOMIC_NAME, times = length(surveys) ) ## vector of species 
temp3 <- as.data.frame(cbind(temp1, temp2)) ## combine them
colnames(temp3) <- c("SurveyID","TAXONOMIC_NAME") #column names 

#add observed abundance to the relevant rows. Since we use left_join it will keep all entries from temp3, so all survey / species combinations, and leave NA if a species was absent
SppSurveyAll <- left_join(temp3, ModelSppAbund, by = c("SurveyID","TAXONOMIC_NAME"))
SppSurveyAll$year <- SurveyYear$year[match(SppSurveyAll$SurveyID, SurveyYear$SurveyID)]

## check that we have the same number of NAs for biomasses and abundances 
length(which(is.na(SppSurveyAll$bio16) == TRUE))
length(which(is.na(SppSurveyAll$abun16) == TRUE))
# yes, we do, which means that if there is no abundance there is also no biomass and vice versa

#and replace NAs with 0 
SppSurveyAll$bio16[which(is.na(SppSurveyAll$bio16) == TRUE)] <- 0
SppSurveyAll$abun16[which(is.na(SppSurveyAll$abun16) == TRUE)] <- 0

SppSurveyAll$decade <- 2
SppSurveyAll$decade[which(SppSurveyAll$year < 2000)] <- 1
SppSurveyAll$decade[which(SppSurveyAll$year > 2009)] <- 3
#check that it works
#test <- SppSurveyAll %>% group_by(decade) %>% summarise(ny <- n_distinct(year), fy = min(year), ly = max(year)) 

#save(SppSurveyAll, file = "../inputs/SppSurveyBiomAbundAllYears.RData")

##### NOW INVERTEBRATES
fish.early.LT.M2 <- rls_bas %>% filter (SiteLat < -40.8) %>% filter (Method == 2)
length(unique(fish.early.LT.M2$SurveyID)) #6915
surveysM2 <- unique(fish.early.LT.M2$SurveyID)

#SurveyYear <- fish.early.LT.M1 %>% group_by(SurveyID) %>% summarise (year = first(year), spp = n_distinct(TAXONOMIC_NAME))

SurveyYearM2 <- fish.early.LT.M2 %>% group_by(SurveyID) %>% summarise (year = first(year))

##
InvSppAbund <- rls_bas %>% 
  filter (SiteLat < -40.8) %>%
  #filter (year < 2000) %>%  #if doing only for the 1990s use this line: 
  filter( GENUS == "Heliocidaris" | GENUS == "Centrostephanus" | GENUS == "Goniocidaris" | GENUS == "Jasus") %>%
  filter (Method == "2") %>% 
  group_by (GENUS, SurveyID) %>% 
  summarise (abunInv = sum(Abundance))

#now sum all urchin genera into one group, because they all are counted as urchins in the model; rename them to model names
InvSppAbund$invert <- NA
InvSppAbund$invert[which(InvSppAbund$GENUS == "Heliocidaris" | InvSppAbund$GENUS == "Centrostephanus" | InvSppAbund$GENUS == "Goniocidaris")] <- "urchins"
InvSppAbund$invert[which(InvSppAbund$GENUS == "Jasus")] <- "lobsters"
unique(InvSppAbund$invert)

## And create a new summary per survey, which is now also scaled by 5 to be comparable to method 1 surveys
InvAbund <- InvSppAbund %>% group_by(invert, SurveyID) %>% 
  summarise (abundInv = sum(abunInv)*5)
rm(InvSppAbund)
invSpecies = c("urchins", "lobsters")

#Now we have abundances of all model species per each survey. But if a species was not present in the survey it will not be recorded, and we do not know for how many surveys a given species was absent from. So from this data we can't estimate mean per survey abundance or sd of abundance. We want to create a file with all surveys for each species and 0 if a species was not present

temp1 <- rep(surveysM2, each = length(invSpecies)) ## vector of surveys by species
temp2 <- rep(invSpecies, times = length(surveysM2) ) ## vector of species 
temp3 <- as.data.frame(cbind(temp1, temp2)) ## combine them
colnames(temp3) <- c("SurveyID","invert") #column names 

#add observed abundance to the relevant rows. Since we use left_join it will keep all entries from temp3, so all survey / species combinations, and leave NA if a species was absent
InvSurveyAll <- left_join(temp3, InvAbund, by = c("SurveyID","invert"))
InvSurveyAll$year <- SurveyYearM2$year[match(InvSurveyAll$SurveyID, SurveyYearM2$SurveyID)]

#and replace NAs with 0 
InvSurveyAll$abundInv[which(is.na(InvSurveyAll$abundInv) == TRUE)] <- 0

#add decade 
InvSurveyAll$decade <- 2
InvSurveyAll$decade[which(InvSurveyAll$year < 2000)] <- 1
InvSurveyAll$decade[which(InvSurveyAll$year > 2009)] <- 3
test <- InvSurveyAll %>% group_by(decade) %>% summarise(ny <- n_distinct(year), fy = min(year), ly = max(year))

#save(InvSurveyAll, file = "../inputs/InvSurveyAbundAllYears.RData")

```

### Data of abundance/bio per survey: Maria only 

```{r warning=FALSE, message=FALSE, eval=T, echo = F, eval = F}
load(file="../inputs/rlsbas_mar2019.RData")
load(file = "../inputs/ModelSpeciesSummary.RData")

#if doing only for the 1990s use this line: 
#fish.early.LT.M1 <- rls_bas %>% filter (SiteLat < -40.8) %>% filter (year < 2000) %>% filter (Method == 1)

MariaLocs = c("Maria Island Reserve", "Maria Island Vincinity", "Maria External")

fish.early.LT.M1 <- rls_bas %>% filter (Location %in% MariaLocs) %>% filter (Method == 1)
length(unique(fish.early.LT.M1$SurveyID)) #1974
surveys <- unique(fish.early.LT.M1$SurveyID)

#SurveyYear <- fish.early.LT.M1 %>% group_by(SurveyID) %>% summarise (year = first(year), spp = n_distinct(TAXONOMIC_NAME))

SurveyYear <- fish.early.LT.M1 %>% group_by(SurveyID) %>% summarise (year = first(year))

##
ModelSppAbund <- rls_bas %>% 
  filter (Location %in% MariaLocs) %>%
  #filter (year < 2000) %>%  #if doing only for the 1990s use this line: 
  filter (TAXONOMIC_NAME %in% ModelSpecies$TAXONOMIC_NAME) %>% 
  filter (Method == "1") %>% 
  group_by (TAXONOMIC_NAME, SurveyID) %>% 
  summarise (bio16 = sum(BioMass, na.rm = T), abun16 = sum(Abundance))

#Now we have  biomases and abundances of all model species per each survey. But if a species was not present in the survey it will not be recorded, and we do not know for how many surveys a given species was absent from. So from this data we can't estimate mean per survey abundance or sd of abundance. We want to create a file with all surveys for each species and 0 if a species was not present

temp1 <- rep(surveys, each = length(ModelSpecies$TAXONOMIC_NAME)) ## vector of surveys by species
temp2 <- rep(ModelSpecies$TAXONOMIC_NAME, times = length(surveys) ) ## vector of species 
temp3 <- as.data.frame(cbind(temp1, temp2)) ## combine them
colnames(temp3) <- c("SurveyID","TAXONOMIC_NAME") #column names 

#add observed abundance to the relevant rows. Since we use left_join it will keep all entries from temp3, so all survey / species combinations, and leave NA if a species was absent
SppSurveyAll <- left_join(temp3, ModelSppAbund, by = c("SurveyID","TAXONOMIC_NAME"))
SppSurveyAll$year <- SurveyYear$year[match(SppSurveyAll$SurveyID, SurveyYear$SurveyID)]

## check that we have the same number of NAs for biomasses and abundances 
length(which(is.na(SppSurveyAll$bio16) == TRUE))
length(which(is.na(SppSurveyAll$abun16) == TRUE))
# yes, we do, which means that if there is no abundance there is also no biomass and vice versa

#and replace NAs with 0 
SppSurveyAll$bio16[which(is.na(SppSurveyAll$bio16) == TRUE)] <- 0
SppSurveyAll$abun16[which(is.na(SppSurveyAll$abun16) == TRUE)] <- 0

SppSurveyAll$decade <- 2
SppSurveyAll$decade[which(SppSurveyAll$year < 2000)] <- 1
SppSurveyAll$decade[which(SppSurveyAll$year > 2009)] <- 3
#check that it works
test <- SppSurveyAll %>% group_by(decade) %>% summarise(ny <- n_distinct(year), fy = min(year), ly = max(year)) 

#save(SppSurveyAll, file = "../inputs/SppSurveyAllYears_Maria.RData")

##### NOW INVERTEBRATES
fish.early.LT.M2 <- rls_bas %>% filter (Location %in% MariaLocs) %>% filter (Method == 2)
length(unique(fish.early.LT.M2$SurveyID)) #1922
surveysM2 <- unique(fish.early.LT.M2$SurveyID)

#SurveyYear <- fish.early.LT.M1 %>% group_by(SurveyID) %>% summarise (year = first(year), spp = n_distinct(TAXONOMIC_NAME))

SurveyYearM2 <- fish.early.LT.M2 %>% group_by(SurveyID) %>% summarise (year = first(year))

##
InvSppAbund <- rls_bas %>% 
  filter (Location %in% MariaLocs) %>%
  #filter (year < 2000) %>%  #if doing only for the 1990s use this line: 
  filter( GENUS == "Heliocidaris" | GENUS == "Centrostephanus" | GENUS == "Goniocidaris" | GENUS == "Jasus") %>%
  filter (Method == "2") %>% 
  group_by (GENUS, SurveyID) %>% 
  summarise (abunInv = sum(Abundance))

#now sum all urchin genera into one group, because they all are counted as urchins in the model; rename them to model names
InvSppAbund$invert <- NA
InvSppAbund$invert[which(InvSppAbund$GENUS == "Heliocidaris" | InvSppAbund$GENUS == "Centrostephanus" | InvSppAbund$GENUS == "Goniocidaris")] <- "urchins"
InvSppAbund$invert[which(InvSppAbund$GENUS == "Jasus")] <- "lobsters"
unique(InvSppAbund$invert)

## And create a new summary per survey, which is now also scaled by 5 to be comparable to method 1 surveys
InvAbund <- InvSppAbund %>% group_by(invert, SurveyID) %>% 
  summarise (abundInv = sum(abunInv)*5)
rm(InvSppAbund)
invSpecies = c("urchins", "lobsters")

#Now we have abundances of all model species per each survey. But if a species was not present in the survey it will not be recorded, and we do not know for how many surveys a given species was absent from. So from this data we can't estimate mean per survey abundance or sd of abundance. We want to create a file with all surveys for each species and 0 if a species was not present

temp1 <- rep(surveysM2, each = length(invSpecies)) ## vector of surveys by species
temp2 <- rep(invSpecies, times = length(surveysM2) ) ## vector of species 
temp3 <- as.data.frame(cbind(temp1, temp2)) ## combine them
colnames(temp3) <- c("SurveyID","invert") #column names 

#add observed abundance to the relevant rows. Since we use left_join it will keep all entries from temp3, so all survey / species combinations, and leave NA if a species was absent
InvSurveyAll <- left_join(temp3, InvAbund, by = c("SurveyID","invert"))
InvSurveyAll$year <- SurveyYearM2$year[match(InvSurveyAll$SurveyID, SurveyYearM2$SurveyID)]

#and replace NAs with 0 
InvSurveyAll$abundInv[which(is.na(InvSurveyAll$abundInv) == TRUE)] <- 0

#add decade 
InvSurveyAll$decade <- 2
InvSurveyAll$decade[which(InvSurveyAll$year < 2000)] <- 1
InvSurveyAll$decade[which(InvSurveyAll$year > 2009)] <- 3
test <- InvSurveyAll %>% group_by(decade) %>% summarise(ny <- n_distinct(year), fy = min(year), ly = max(year))

#save(InvSurveyAll, file = "../inputs/InvSurveyAllYears_Maria.RData")

```

### Mean biom/abundance 

```{r, eval = F}
load(file = "../inputs/SppSurveyBiomAbundAllYears.RData")
load(file = "../inputs/InvSurveyAbundAllYears.RData")
load(file = "../inputs/ModelSpeciesSummary.RData")
#load(file = "../inputs/ModelSppStats.RData")

## now pool some species into model groups to calculate statistics per model group, not taxonomic group. So we need to match taxonomic names with model names
ModelSpp = c("Caesioperca rasor", "Cheilodactylus spectabilis" ,"Dinolestes lewini" ,"Latridopsis forsteri" ,"Aplodactylus arctidens" ,"Notolabrus tetricus", "Notolabrus fucicola" ,"Cephaloscyllium laticeps", "Meuschenia australis" ,"Acanthaluteres vittiger" ,"Pseudophycis bachus" ,"Trachinops caudimaculatus", "Olisthops cyanomelas" ,"Pentaceropsis recurvirostris", "Meuschenia freycineti" ,"Pictilabrus laticlavius", "urchins", "lobsters", "predator")
MatchNames <- list()
MatchNames$modelName <- c("C_rasor", "C_spectabilis" ,"D_lewini" ,"L_forsteri" ,"A_arctidens" ,"Notolabrus", "Notolabrus" ,"C_laticeps", "leatherjack" ,"leatherjack" ,"P_bachus" ,"T_caudimaculatus", "O_cyanomelas" ,"Boarfish", "M_freycineti" ,"P_laticlavius", "urchins", "lobsters", "predator")
MatchNames$sppName <- ModelSpp
MatchNames$plotName <- c("Caesioperca","Cheilodactylus", "Dinolestes", "Latridopsis", "Aplodactylus", "Notolabrus", "Notolabrus", "Cephaloscyllium", "leatherjackets", "leatherjackets", "Pseudophycis", "Trachinops", "Olisthops", "Pentaceropsis", "Meuschenia", "Pictilabrus", "urchins", "lobsters", "predator")

ModelSpecies$modelName <- MatchNames$modelName[match(ModelSpecies$TAXONOMIC_NAME, MatchNames$sppName)]
ModelSpecies$plotName <- MatchNames$plotName[match(ModelSpecies$TAXONOMIC_NAME, MatchNames$sppName)]

#Also match names in the per survey dataset
SppSurveyAll$modelName <- MatchNames$modelName[match(SppSurveyAll$TAXONOMIC_NAME, MatchNames$sppName)]

MeanLobWeight = 150 #assume mean lobster weighs 150g
MeanUrcWeight = 5 # mean urchin 5g

InvSurveyAll$meanWgt <- NA
InvSurveyAll$meanWgt[which(InvSurveyAll$invert == "urchins")] <- MeanUrcWeight
InvSurveyAll$meanWgt[which(InvSurveyAll$invert == "lobsters")] <- MeanLobWeight
InvSurveyAll$bioInv <- InvSurveyAll$abundInv * InvSurveyAll$meanWgt

## Statistics per decade

#Now we can calculate per survey biomass and abundance statistics 
ModelSppStatistics <- SppSurveyAll %>% group_by(modelName, decade) %>%
  summarise(meanBio = mean(bio16), sdBio = sd(bio16), maxBio = max(bio16), medianBio = median(bio16), meanAbun = mean(abun16), sdAbun = sd(abun16), maxAbun = max(abun16), q90abun = quantile(abun16, probs = 0.9), q80bio = quantile(abun16, probs = 0.8), q70abun = quantile(abun16, probs = 0.70), q60abun = quantile(abun16, probs = 0.60), q50abun = quantile(abun16, probs = 0.50))

#Do the same for intertebrates. Remember WE ALREADY SCALED EVERYTHING BY 5 to match survey area with method 1
InvSppStatistics <- InvSurveyAll %>% group_by(invert, decade) %>%
  summarise(meanBio = mean(bioInv), sdBio = sd(bioInv), maxBio = max(bioInv), medianBio = median(bioInv), meanAbun = mean(abundInv), sdAbun = sd(abundInv), maxAbun = max(abundInv), q90abun = quantile(abundInv, probs = 0.9), q80bio = quantile(abundInv, probs = 0.8), q70abun = quantile(abundInv, probs = 0.70), q60abun = quantile(abundInv, probs = 0.60), q50abun = quantile(abundInv, probs = 0.50))

AllSppStatistics <- rbind(ModelSppStatistics, InvSppStatistics)
AllSppStatistics$modelName[which(AllSppStatistics$invert == "lobsters")] <- "lobsters"
AllSppStatistics$modelName[which(AllSppStatistics$invert == "urchins")] <- "urchins"

AllSppStatisticsDecade <- AllSppStatistics

## Statistics per year
ModelSppStatistics <- SppSurveyAll %>% group_by(modelName, year) %>%
  summarise(meanBio = mean(bio16), sdBio = sd(bio16), maxBio = max(bio16), medianBio = median(bio16), meanAbun = mean(abun16), sdAbun = sd(abun16), maxAbun = max(abun16), q90abun = quantile(abun16, probs = 0.9), q80bio = quantile(abun16, probs = 0.8), q70abun = quantile(abun16, probs = 0.70), q60abun = quantile(abun16, probs = 0.60), q50abun = quantile(abun16, probs = 0.50))

InvSppStatistics <- InvSurveyAll %>% group_by(invert, year) %>%
  summarise(meanBio = mean(bioInv), sdBio = sd(bioInv), maxBio = max(bioInv), medianBio = median(bioInv), meanAbun = mean(abundInv), sdAbun = sd(abundInv), maxAbun = max(abundInv), q90abun = quantile(abundInv, probs = 0.9), q80bio = quantile(abundInv, probs = 0.8), q70abun = quantile(abundInv, probs = 0.70), q60abun = quantile(abundInv, probs = 0.60), q50abun = quantile(abundInv, probs = 0.50))

AllSppStatistics <- rbind(ModelSppStatistics, InvSppStatistics)
AllSppStatistics$modelName[which(AllSppStatistics$invert == "lobsters")] <- "lobsters"
AllSppStatistics$modelName[which(AllSppStatistics$invert == "urchins")] <- "urchins"

AllSppStatisticsYear <- AllSppStatistics

## Statistics last 5 years - get average for comparison
ModelSppStatistics <- SppSurveyAll %>% filter (year > 2013) %>% group_by(modelName) %>%
  summarise(meanBio = mean(bio16), sdBio = sd(bio16), maxBio = max(bio16), medianBio = median(bio16), meanAbun = mean(abun16), sdAbun = sd(abun16), maxAbun = max(abun16), q90abun = quantile(abun16, probs = 0.9), q80bio = quantile(abun16, probs = 0.8), q70abun = quantile(abun16, probs = 0.70), q60abun = quantile(abun16, probs = 0.60), q50abun = quantile(abun16, probs = 0.50))

InvSppStatistics <- InvSurveyAll %>% filter (year > 2013) %>% group_by(invert) %>%
  summarise(meanBio = mean(bioInv), sdBio = sd(bioInv), maxBio = max(bioInv), medianBio = median(bioInv), meanAbun = mean(abundInv), sdAbun = sd(abundInv), maxAbun = max(abundInv), q90abun = quantile(abundInv, probs = 0.9), q80bio = quantile(abundInv, probs = 0.8), q70abun = quantile(abundInv, probs = 0.70), q60abun = quantile(abundInv, probs = 0.60), q50abun = quantile(abundInv, probs = 0.50))

colnames(InvSppStatistics) <- c("modelName", colnames(InvSppStatistics)[2:13])
AllSppStatistics <- rbind(ModelSppStatistics, InvSppStatistics)
AllSppStatisticsRecent <- AllSppStatistics

## and now make a file of relative change 
compareBio <- AllSppStatisticsDecade %>% filter (decade == 1) %>% select(modelName, meanBio, meanAbun)
compareBio$newBio <- AllSppStatisticsRecent$meanBio[match(compareBio$modelName, AllSppStatisticsRecent$modelName)]
compareBio$newAbun <- AllSppStatisticsRecent$meanAbun[match(compareBio$modelName, AllSppStatisticsRecent$modelName)]

## in plot data we use (scenario-baseline)/baseline; baseline is the calibration dataset; so we will get similar estimate of (latest - initial)/initial

compareBio$relBioChange <- (compareBio$newBio - compareBio$meanBio)/compareBio$meanBio
compareBio$relAbunChange <- (compareBio$newAbun - compareBio$meanAbun)/compareBio$meanAbun

#compareBioMaria <- compareBio

#save(AllSppStatisticsDecade, file = "../inputs/AllSppStatisticsDecade.RData")
#save(AllSppStatisticsYear, file = "../inputs/AllSppStatisticsYear.RData")
#save(AllSppStatisticsRecent, file = "../inputs/AllSppStatisticsRecent.RData")
#save(compareBio, file = "../inputs/relativeBioForPlots.RData")
#save(compareBioMaria, file = "../inputs/relativeBioMariaForPlots.RData")


```

### Biomass/Abund for calibration and testing 

```{r}
#load file from earlier analyses (2 years ago!)
load(file = "../inputs/ModelSpeciesSummary.RData")

#load new files from survey summaries
load(file = "../inputs/AllSppStatisticsDecade.RData")
load(file = "../inputs/AllSppStatisticsYear.RData")

#new file for calibration - check (after two years that everything is still calcualted properly)
SppCalibration <- AllSppStatisticsDecade %>% filter (decade == 1) %>% select(modelName, meanBio, meanAbun)
SppCalibration$scaledAbun <- SppCalibration$meanAbun/max(SppCalibration$meanAbun)
SppCalibration$scaledBiom <- SppCalibration$meanBio/max(SppCalibration$meanBio)

#compare it with the old files 
load(file = "modelParams/mariaParamsMs.RData")
#YAY, all is the same. Scaled abundance and biomass, as well as biomass per m2 is the same. 

#now save biomasses and abundances from the last decade or from the last 5 years for comparison 
SppOutput5y <- AllSppStatisticsYear %>% filter (year > 2013) %>% select(modelName, meanBio, meanAbun)
#save(SppOutput5y, file = "../outputs/meanAbundBioLast5y.RData")
SppOutputInit <- AllSppStatisticsYear %>% filter (year < 2000) %>% select(modelName, meanBio, meanAbun)
save(SppOutputInit, file = "../outputs/meanAbundBioLastInit.RData")


## The code below was just used to get calibration data. It all seems to work, but might not be all necessary
# load(file = "../inputs/ModelSppStats.RData")
# #And add a general predator
# ModelSppStatistics <- add_row(ModelSppStatistics)
# dim(ModelSppStatistics)
# ModelSppStatistics[dim(ModelSppStatistics)[[1]],1] <- "predator"
# ModelSppStatistics[dim(ModelSppStatistics)[[1]],2] <- 500 #mean biomass of a predator
# ModelSppStatistics[dim(ModelSppStatistics)[[1]],6] <- 0.5 #mean abundance of a predator
# load(file = "../inputs/meanAbundBefore2000.RData")

## this is now renamed and done differently but the code above will show how to get annual or decadal statistics 

# ModelSummaryFinal$meanAbOLD <- fishAbund$meanAb[match(ModelSummaryFinal$modelName, fishAbund$modelName)]
# ModelSummaryFinal$meanBioOLD <- fishAbund$meanBio[match(ModelSummaryFinal$modelName, fishAbund$modelName)]
# ModelSummaryFinal$sdAbOLD <- fishAbund$sdAb[match(ModelSummaryFinal$modelName, fishAbund$modelName)]
# ModelSummaryFinal$sdBioOLD <- fishAbund$sdBio[match(ModelSummaryFinal$modelName, fishAbund$modelName)]
# ModelSummaryFinal$scaledAbun <- ModelSummaryFinal$meanAb/max(ModelSummaryFinal$meanAb)
# ModelSummaryFinal$scaledBiom <- ModelSummaryFinal$meanBio/max(ModelSummaryFinal$meanBio)
# ModelSppStatistics <- ModelSummaryFinal
#write.csv(ModelSppStatistics, file = "../inputs/ModelSppStats.csv")
#save(ModelSppStatistics, file = "../inputs/ModelSppStats.RData")

## save relative abundance and biomass data to the model param file 
# mariaParams <- read.csv(file = "../modelParams/Tasm_parameters.csv")
# mariaParams$scaledAb <- round(ModelSummaryFinal$scaledAbun[match(mariaParams$species, ModelSummaryFinal$modelName)],6)
# mariaParams$scaledBio <- round(ModelSummaryFinal$scaledBiom[match(mariaParams$species, ModelSummaryFinal$modelName)],6)
# mariaParams$BioM2 <- (round(ModelSummaryFinal$meanBio[match(mariaParams$species, ModelSummaryFinal$modelName)],6)/500)
#write.csv(mariaParams, file = "../modelParams/Tasm_paramsN19.csv")

#for Trachinops mean abundance is 110 but it gives diffcult calibration so I set to lower number for now (note that here we only record abundance above 2cm, whereas model counts all abundance and assumes same size slopes for all species)
#fishAbund$meanAb[which(fishAbund$modelName == "T_caudimaculatus")] <- 60
#fishAbund$meanAb[which(fishAbund$modelName == "urchins")] <- 100 #instead of 230, which drives the system nuts I think
#save(fishAbund, file = "meanAbundBefore2000.RData")
#For lobsters LW conversion is as 
#W = 0.000285*L^3.114 males
#W = 0.000271*L^3.135 females
#to convert from carapace length in mm to grams

```

### Species params: Fishbase, diet prediction

```{r}
load(file = "../inputs/ModelSpeciesSummary.RData")

ModelSpp <- ModelSpecies$TAXONOMIC_NAME

#get maximum size from the survey data: surveys are selected for the model area

  MaxSize <- rls_bas %>%
    filter (TAXONOMIC_NAME %in% ModelSpp) %>%
      group_by (TAXONOMIC_NAME, year) %>% # maximum size observed in a year in a given Location
        summarise (sizeMax = max(SizeClass)) %>% 
          group_by(TAXONOMIC_NAME) %>%
            top_n(3, sizeMax) %>% summarise (MaxSizeMed = median(sizeMax))
  
ModelSpecies <- full_join(ModelSpecies, MaxSize, by = "TAXONOMIC_NAME")
  
ModelSpecies$therm_count <- thermal$count[match(ModelSpecies$TAXONOMIC_NAME, thermal$SPECIES_NAME)] 
ModelSpecies$CTMq05 <- thermal$CTMq05[match(ModelSpecies$TAXONOMIC_NAME, thermal$SPECIES_NAME)]
ModelSpecies$CTMq95 <- thermal$CTMq95[match(ModelSpecies$TAXONOMIC_NAME, thermal$SPECIES_NAME)]
ModelSpecies$midpoint <- thermal$MP..5.95.[match(ModelSpecies$TAXONOMIC_NAME, thermal$SPECIES_NAME)]
ModelSpecies$comname <- ComNames$COMMON_NAME[match(ModelSpecies$TAXONOMIC_NAME, ComNames$TAXONOMIC_NAME)]

## next add parameters for length-weight conversion 
ModelSpecies$LWa <- lw$A[match(ModelSpecies$TAXONOMIC_NAME, lw$SPECIES)] 
ModelSpecies$LWb <- lw$B[match(ModelSpecies$TAXONOMIC_NAME, lw$SPECIES)]

#the median Lmax estimation is not always good, so I have a datafile corrected by experts
ModelSpecies$LmaxCor <- Lmax$LmaxCorrect[match(ModelSpecies$TAXONOMIC_NAME, Lmax$TAXONOMIC_NAME)]
ModelSpecies$vbKcor <- Lmax$Kvb_correct[match(ModelSpecies$TAXONOMIC_NAME, Lmax$TAXONOMIC_NAME)]  

##Now add parameters from the fishbase lifeHistory tool 
#first select only species that are in the model 

ModelSppFB <- FBdata %>% filter (TAXONOMIC_NAME %in% ModelSpp)
ModelSpp_Fishbase <- full_join(ModelSpecies, ModelSppFB, by = "TAXONOMIC_NAME")

ModelSpecies$vbKfb <- ModelSppFB$K[match(ModelSpecies$TAXONOMIC_NAME, ModelSppFB$TAXONOMIC_NAME)] 
ModelSpecies$Lmaxfb <- ModelSppFB$Lmax[match(ModelSpecies$TAXONOMIC_NAME, ModelSppFB$TAXONOMIC_NAME)] 

### and now add the diet prediction data 
#First create vectors for all the species and genera for which we have diet predictiton data 
dietSpecies = as.character(unique(diet$Species))
dietGenera = as.character(unique(diet$Genus))
#dietFamily = unique(dietData$Family)

## and the same for model species
ModelSpecies$genus <- rls_bas$GENUS[match(ModelSpecies$TAXONOMIC_NAME, rls_bas$TAXONOMIC_NAME)]

ModelGenera <- as.character(unlist(unique(ModelSpecies$genus)))
#ModelSpecies <- as.character(unlist(unique(ModelSpecies$TAXONOMIC_NAME)))
#ModelFamily <- unique(MarVerts$Family)

#ModelGenera[which(ModelGenera %in% dietGenera)] #all model genera are in 
#ModelSpecies[which(ModelSpecies %in% dietSpecies)]
#ModelFamily[which(ModelFamily %in% dietFamily)]

## from the large diet PREDICTION matrix extract only information relevant to the model species and genera and size groups of fish consumers
ModelDiets <- diet %>% filter(Species %in% ModelSpp) %>% group_by(WWtr, MainPrey, Species) %>% summarise (fish = n_distinct(Fish), dietProp = sum(pDietpc)/fish, preyWmean = mean(preyWW), preyWsd = sd(preyWW), preySmean = mean(predictdietsize.mm.), preySsd = sd(predictdietsize.mm.), MR = mean(ppmr), LR =mean(pplr), fromSp = first(fromSp), fromGe = first(fromGe), fromFa = first(fromFa)) #%>% filter(fish>5) %>% filter (dietProp > 5)

#get total number of size groups available in the diet prediction data  for all model species. it would be better to simply use the diet prediction code to run for the range of model size groups. But at the moment we are using outputs generated from the diet prediction code to the RLS observations in Tasmania. Given that predictions are very general this is sufficient for now 
NofSG <- diet %>% filter(Species %in% ModelSpp) %>% group_by(Species) %>% summarise(sizeGr = n_distinct(WWtr))

ModelDiets2 <- full_join(ModelDiets, NofSG, by ="Species")
 
#Get a summary of diet predictions for species and prey types. What is the predicted proportion and PPMR of different prey types for model species 
MeanModelDiets <- ModelDiets2 %>% group_by(Species, MainPrey) %>% summarise(NoFish = sum(fish), NoFishSizeGroups = n_distinct(WWtr), meanWgtFish = mean(WWtr), sdWgtFish = sd(WWtr), dietProp = round(sum(dietProp)/first(sizeGr),0), PPMRmean = round(mean(MR),0), PPMRsd = round(sd(MR, na.rm = T),0), fromSp = first(fromSp), fromGe = first(fromGe), fromFa = first(fromFa), ) #get correct diet proporton in %

rm(ModelDiets, ModelDiets2, NofSG)

#Mean model diets shows the proportion of various diets 

SpeciesPPMR <- MeanModelDiets %>% group_by(Species) %>% summarise(dietTypes = n_distinct(MainPrey), MRmean = round(mean(PPMRmean),0), MRsd = round(mean(PPMRsd, na.rm = T),0), fromSp = first(fromSp), fromGe = first(fromGe), fromFa = first(fromFa))
SpeciesPPMR$dietConf <- SpeciesPPMR$fromSp + SpeciesPPMR$fromGe + SpeciesPPMR$fromFa

ModelSpecies$PPMRmean <- SpeciesPPMR$MRmean[match(ModelSpecies$TAXONOMIC_NAME, SpeciesPPMR$Species)] 
ModelSpecies$PPMRsd <- SpeciesPPMR$MRsd[match(ModelSpecies$TAXONOMIC_NAME, SpeciesPPMR$Species)]
ModelSpecies$dietConf <- SpeciesPPMR$dietConf[match(ModelSpecies$TAXONOMIC_NAME, SpeciesPPMR$Species)]

#FishBenDiets <- MeanModelDiets %>% filter(MainPrey == "epif" | MainPrey == 'epcr' | MainPrey == "fish" | MainPrey == 'plcr') %>% group_by (Species, MainPrey) %>% summarise (MRmean = mean(MRmean), MRsd = mean(MRsd))

#save(ModelSpecies, file = "../inputs/ModelSpeciesSummaryMore.RData")

```

### Estimating h: maximum intake coefficient

Daily food intake for all RLS species has been calculated by Soler et al. (2014) based on diets, sizes and average site temperature. The equation is from Palomares and Pauly (1989) and is empirically derived: 
lnQ/B = −0.1775 − 0.2018 lnW + 0.6121 lnT + 0.5156 lnA + 1.26F
where Q/B is the % intake per day, A is the aspect ratio of the tail and F is set to 1 for carnivorous fish and 0 for all other fish. The values of daily intake in these calculations varies around 1-8% for differenet species and sizes, but is bigger for herbivores. These values are generally consistent with experimental feeding rates

We can use the estimates for a simple body size intake linear regression, that will give us allometric relationship between consumption and body size (constant and exponent). Note, these intake values are realised intakes ant not the maximum intake. So we need to correct them for the feeding level to get to the maximum intake. If we make various assumptions about the feeding level we could infer the maximum intake rate at different body sizes. For this we assume that feeding level changes smoothly and monotonically with body size. This is not entirely true as some sizes might experience drops in feeding level, but for a general approximation it will do

#### h for model species only

```{r warning=FALSE, message=FALSE, warning=FALSE, echo=F}
load(file = "../inputs/ModelSpeciesSummaryMore.RData")
#diet = read.csv (file = "../inputs/dietpred.csv")

#assumptions about food limitation 
f_min = 0.6 # assumed value for feeding level at minimum body size
f_max = 0.9 # assumed value for feeding level at maximum body size
m1_1 = 0.15 #steepness value to give a smooth curve 

#check how the curve looks: 
ww_inf = 1000 #let's say maximum body size is 1000g
ww = seq(from = 0, to = ww_inf)
foodlim1 <- f_min + (f_max-f_min)*exp(-m1_1*(ww_inf/ww)) # food satiation versus body size 
#this is how feeding level could increase with body size at the intraspecific level 
plot(ww, foodlim1, type = 'l')

#get Wmax for all model species
ModelSpecies$Wmax <- ModelSpecies$LWa * ModelSpecies$Lmax^ ModelSpecies$LWb

## list of model species
ModelSpp <- ModelSpecies$TAXONOMIC_NAME

# loop through the list of model species, fit linear regression between food consumed (in grams) and consumers body weight 
ConsEst <- list()

for (i in 1:length(ModelSpp)) {
  
Intake <- diet %>% filter (Species %in% ModelSpp[i])

Intake$Wmax <- ModelSpecies$Wmax[match(Intake$Species, ModelSpecies$TAXONOMIC_NAME)]

#linear regression to estimate daily consumption - weight relationship
# daily consumption is predicted based on the equation above
temp = lm(log(Intake$FoodCons) ~ log(Intake$WWtr))
ConsEst$coef[i] <- exp(temp$coefficients[[1]])
ConsEst$exp[i] <- temp$coefficients[[2]]

# the consumption estimates above are realised intake, not maximum intake. To get maximum intake we have to assume some level of food limitation. Let's assume that food limiation or satiation changes with body size as outlined above. Now add a column of feeding level to the data set. It will depend on the ratio between body size to maximum size 
Intake$foodlim <- f_min + (f_max-f_min)*exp(-m1_1*(Intake$Wmax/Intake$WWtr))

#Now the maximum consumption would simply be the ratio from the estimated consumption by food limitation
maxcon = Intake$FoodCons/Intake$foodlim
# and we can fit a regression on how max consumption  scales with body size 
temp2 = lm(log(maxcon) ~ log(Intake$WWtr))

#Save the coefficient and exponents values (transformed from the log log scale to that used in the model)
ConsEst$coefMax[i] <- exp(temp2$coefficients[[1]])
ConsEst$expMax[i] <- temp2$coefficients[[2]]
ConsEst$TAXONOMIC_NAME[i] <- ModelSpp[i]
}

# Add these values into the final data file. Note the coefficient is divided by 100 because thi
ModelSpecies$ConsConst <- (ConsEst$coef[match(ModelSpecies$TAXONOMIC_NAME, ConsEst$TAXONOMIC_NAME)])/100
ModelSpecies$ConsExp <- ConsEst$exp[match(ModelSpecies$TAXONOMIC_NAME, ConsEst$TAXONOMIC_NAME)] 
ModelSpecies$ConsConstMax <- (ConsEst$coefMax[match(ModelSpecies$TAXONOMIC_NAME, ConsEst$TAXONOMIC_NAME)])/100
ModelSpecies$ConsExpMax <- ConsEst$expMax[match(ModelSpecies$TAXONOMIC_NAME, ConsEst$TAXONOMIC_NAME)] 

## Note the exponent of daily food consumption with body weight is 0.79-0.81
round(ModelSpecies$ConsExpMax, 2)

## consumption constant (higher for two herbivore species)
round(ModelSpecies$ConsConstMax, 2) 

#or get annual values, as used in mizer
round(ModelSpecies$ConsConstMax, 2)*365

##
##Alternatively, we could use default mizer estimations of h from Blanchard et al. 2004 (?). They use Winf and von Bertalanffy K.
K_vb = ModelSpecies$vbKfb # VB k value from fishbase
K_vbC = ModelSpecies$vbKcor #Vb k value from literature on specific species or talking to experts. You can see how different it can be!
Winf = ModelSpecies$Wmax

#assumed feeding level
f0 = 0.8
alpha = 0.6*0.6 #here we account for 0.6 assimilation efficiency and 0.6 growth cost (inefficiency)

ModelSpecies$h_mizer = (3*K_vb)/(alpha*f0) * Winf^(1/3)
ModelSpecies$h_mizerC = (3*K_vbC)/(alpha*f0) * Winf^(1/3)

#plot(ModelSpecies$Wmax, ModelSpecies$h_mizer)

ConsParams <- ModelSpecies %>% select (TAXONOMIC_NAME, ConsExp, ConsExpMax, ConsConst, ConsConstMax, LmaxCor, vbKcor, Lmaxfb, vbKfb, PPMRmean, PPMRsd, dietConf, h_mizer, h_mizerC, Wmax) %>% mutate(ConsConstMaxY = ConsConstMax*365) 

knitr::kable(ConsParams, digits = 3)

```

TODO - replace units of g/g/year to g/g^n/year



The summary from analyses above shows that assuming feeding level of about 0.6 across all body size and using empirical equation based daily intake values, we get the h value of about 50 g/g/year for most species and ca 150 g/g/year for herbivores. The estimated maximum consumption exponent n is around 0.8, which is much higher than DEB or mizer assumptions of 2/3. To get the maximum intake exponent to be close to 2/3 and still match the daily intake estimates from the Pauly and Palomares equation (or other empirical studies), we need to assume that for many fish species feeding level increases with body size from 0.5 to somewhere around 0.9. In this case the fitted exponent is ca 0.7-0.75 and h is 40-60g/g/year (ConsConstMaxY column) and 200g/g/year in herbivores. You can see that if you play with the feeding level assumptions above

If we use mizer default h estimation (based on alpha, VB_k and feeding level) we find that it is extremely sensitive to the VB k parameter, which is highly uncertain in our species. So the h estimate can vary between 30 and 170 for the same species, because k estimates for this species vary between 1.4 to 0.26! However for species where k values seem reasonabble (e.g. Notolabrus) the mizer default values are about half of what we get based on daily intake estimation (ca 20-30 g/g/year for mizer default compared to 40-60 g/g/year for my estimations). If we reduce alpha from 0.6 to 0.6*0.6 (which now accounts both for assimilation efficiency and growth conversion cost used in this study)and increase the feeding level to 0.8 we still get h values about 50% lower than the estimates based on empirical intake assumptions. 

Next, we can compare these estimates of h to the Dynamic Energy Budget (DEB) theory. DEB assumes that intake is always at maximum (feeding level =1). The range of surface area specific maximum assimilation rate in DEB ranges at 0.06-0.19 g cm-2 day-1 (DEB online database, Kooijman and Lika, 2014), which is approximately 0.06-0.2 g/g/day or 20-73 g/g/year given that DEB and mizer assumptions that maximum intake scales with body sizes to the power of 2/3. In fish growth model (Audzijonyte & Richards, 2018) intake is determined by structural weight only, so the mass specific constant is higher than in models where intake is based on total weight. The constant is 0.1 g/g/day (or 36.5 g/g/years) and leads to emergent daily intake of 0.5-4%  (assuming assimilation efficiency of 0.7-0.8). In mizer default assimilation rates are slighly lower (0.6) so the maximum intake rate should be a bit higher, or closer to 40-50g/g/year. Indeed, in the standard community model of mizer the maximum food intake constant h = 40 g/g/year (Hartvig et al. 2011), which is very similar to the estimate from the daily food intake or from DEB. This suggests that at least for the model species mizer default calculations would give h values that are too low, and we should aim for the h values that are in the range of 40-50g/g/year. 

#### h to Wmax across many species

Now we can repeat similar analyses for the entire list of species in the Soler et al. dataset

```{r}
#assumptions 
f_min = 0.5 # assumed value for feeding level at minimum body size
f_max = 0.9 # assumed value for feeding level at maximum body size
m1_1 = 0.15 #steepness value to give a smooth curve 


AllSpp <- unique(diet$Species)
#are there any na?
length(which(is.na(diet$Lmax) == T))
#get only data without NA for Lmax
dietForRegr <- diet[which(is.na(diet$Lmax) == F),]
length(which(is.na(dietForRegr$Lmax) == T))
plot(unique(dietForRegr$Lmax))
#now add LW data to get Wmax
dietForRegr$LWa <- lw$A[match(dietForRegr$Species, lw$SPECIES)]
dietForRegr$LWb <- lw$B[match(dietForRegr$Species, lw$SPECIES)]
length(which(is.na(dietForRegr$LWa) == T))
#now get Wmax 
dietForRegr$Wmax <- dietForRegr$LWa*dietForRegr$Lmax^dietForRegr$LWb
plot(unique(log(dietForRegr$Wmax)))
#some species has too small wmax values, let's only use those that are biiger than 10
dietForRegr <- dietForRegr[which(dietForRegr$Wmax > 10),]

#list of species
AllSpp <- unique(dietForRegr$Species)

# loop through the list of model species, fit linear regression between food consumed (in grams) and consumers body weight 
ConsEst <- list()

for (i in 1:length(AllSpp)) {
  
Intake <- dietForRegr %>% filter (Species %in% AllSpp[i])

#linear regression to estimate daily consumption - weight relationship
# daily consumption is predicted based on the equation above
temp = lm(log(Intake$FoodCons) ~ log(Intake$WWtr))
ConsEst$coef[i] <- exp(temp$coefficients[[1]])
ConsEst$exp[i] <- temp$coefficients[[2]]

# the consumption estimates above are realised intake, not maximum intake. To get maximum intake we have to assume some level of food limitation. Let's assume that food limiation or satiation changes with body size as outlined above. Now add a column of feeding level to the data set. It will depend on the ratio between body size to maximum size 
Intake$foodlim <- f_min + (f_max-f_min)*exp(-m1_1*(Intake$Wmax/Intake$WWtr))

#Now the maximum consumption would simply be the ratio from the estimated consumption by food limitation
maxcon = Intake$FoodCons/Intake$foodlim
# and we can fit a regression on how max consumption changes scales with body size 
temp2 = lm(log(maxcon) ~ log(Intake$WWtr))

#Save the coefficient and exponents values (tranformed from the log log scale to that used in the model)
ConsEst$coefMax[i] <- exp(temp2$coefficients[[1]])
ConsEst$expMax[i] <- temp2$coefficients[[2]]
ConsEst$TAXONOMIC_NAME[i] <- AllSpp[i]
}

ConsResAllSpp <- as.data.frame(cbind((ConsEst$coef/100), ConsEst$exp, (ConsEst$coefMax/100), ConsEst$expMax))
ConsResAllSpp$Species <- AllSpp
ConsResAllSpp$Wmax <- dietForRegr$Wmax[match(ConsResAllSpp$Species, dietForRegr$Species)]

colnames (ConsResAllSpp) <- c("coef", "exp", "coefMax", "expMax", "Species", "Wmax")

ConsResAllSpp <- ConsResAllSpp[which(is.na(ConsResAllSpp$expMax) == F),]

round(ConsResAllSpp$exp,2)
round(ConsResAllSpp$coef,3)
round(ConsResAllSpp$expMax,2)
mean(ConsResAllSpp$expMax)
round(ConsResAllSpp$coefMax,2)
#or yearly
round(ConsResAllSpp$coefMax,2)*365
mean((ConsResAllSpp$coefMax))

#or for all species 
plot(log(ConsResAllSpp$Wmax), (ConsResAllSpp$coefMax))

#second regression to get h scaling with Wmax
h_model <- lm(log(ConsResAllSpp$coefMax) ~ log((ConsResAllSpp$Wmax/1000)))

#intercept exp(a) of the model
exp(h_model$coefficients[[1]])
#slope of the model
h_model$coefficients[[2]]

#to account for large number of herbivores we use slighly lower intercept and the final equation is 
#mariaParams$h = 50 * (mariaParams$w_inf/1000)^0.15

```

### Estimating ks across species

By default in mizer and in many MSS model ks = h*0.12. This is based on the assumption that critical feeding level is 0.2 and that assimilation efficiency is 0.6. So intake will just cover the maintenance costs at the critical feeding level (0.6x0.2). For the h of 40g/g/year (see above) this would give ks values of 4.8 g/g/year  and, since h increases with maximum body size, ks would also be larger in large bodied fish. However, critical feeding level in small and large bodied species is unlikely to be similar and there is good evidence that "cost of life" of mass-specific metabolic rates are higher in small bodied species. 

The average mass specific maintenance cost of structure at 20°C temperature in DEB is 20 J cm-3 day-1, but in slow growing vertebrates can be as low as 10 J cm-3 day-1 (Kooijman 2000). For the cod model we assumed maintenance of 10 J cm-3 day-1 (cold water), which translates to 0.003 g g-1 day-1, assuming 1g of structure mass equals 3000J and 1cm3 of wet weight is 1g (van der Veer et al. 2009). This translates to 1.1 g/g/year, but remember the exponent is 1 with structural mass. While reserves don’t need maintenance in DEB, the R pool here includes reserves and gonads and a small maintenance cost (cR) is used, set at 10% of cS. These values give an emergent total maintenance cost of an adult individual at 40-70% of its daily energy intake


```{r}

#Get DEB parameters 

#get the data file and make a matrix
load(file = '../inputs/debdata.Rda')
Nspecies <- length(debdata$allStat)

# get all values of p_M, v, and the species names
SpNames <- vector(length = Nspecies)
fam <- vector(length = Nspecies) 
order <- vector(length = Nspecies)
class <- vector(length = Nspecies)
zoom <- vector(length = Nspecies) #zoom factor 21
Fm <- vector(length = Nspecies) #Fm = max spec searching rate 22
alfa <- vector(length = Nspecies) #alfa = digestion efficiency 23
ffae <- vector(length = Nspecies) #ffae = food to feased efficiency 24 
v <- vector(length = Nspecies) #v = energy conductance 25
#kapppa <- vector(length = Nspecies) #kappa = allocaiton to soma 26
p.M <- vector(length = Nspecies) #p.M = vol. spec som maintenance 28
p.T <- vector(length = Nspecies) #p.T = surf specific somatic maint 29
k.J <- vector(length = Nspecies)#k.J - maturity maint rate 30
E.G <- vector(length = Nspecies) # E.G - spec cost of structure 31
Arrh <- vector(length = Nspecies)#Arrh = arrhenius temp 36
funcres <- vector(length = Nspecies)#funcres = functional response scaled 38

#DEBparams = data.frame(NA, nrow = length(Nspecies), ncol = 8)

for(i in 1:Nspecies){
  
SpNames[i] <- debdata$allStat[[i]][[1]]
fam[i] <- debdata$allStat[[i]][[5]]
order[i] <- debdata$allStat[[i]][[6]]
class[i] <- debdata$allStat[[i]][[7]]
zoom[i] <- debdata$allStat[[i]][[21]]
Fm[i] <- debdata$allStat[[i]][[22]] # all the same. 6.5
alfa[i] <- debdata$allStat[[i]][[23]] # mostly all at 0.8
ffae[i] <- debdata$allStat[[i]][[24]] #all at 0.10
v[i] <- debdata$allStat[[i]][[25]] # does not look that good
#kappa[i] <- debdata$allStat[[i]][[26]]
p.M[i] <- debdata$allStat[[i]][[28]]
#p.T[i] <- debdata$allStat[[i]][[29]]
k.J[i] <- debdata$allStat[[i]][[30]] # not good, too similar
E.G[i] <- debdata$allStat[[i]][[31]]
Arrh[i] <- debdata$allStat[[i]][[36]]
funcres[i] <- debdata$allStat[[i]][[38]]

}

debparams <- cbind(SpNames, fam, order, class, zoom, Fm, alfa, ffae, v, p.M, k.J, E.G, Arrh, funcres)
debparams[which(debparams == 0)] <- NA #replace zero's with NA because they are actually NAs not zeros

## 
vectFish <- which(class == "Actinopterygii")
vectShark <- which(class == "Chondrichthyes")
debFish <- debparams[vectFish,]

#Plot zoom factor against metabolic rate, we can see that are few species have very high metabolic rates
plot(debFish[,5], debFish[,10], ylim = c(0, 200), xlab = "zoom factor", ylab = "p.M")

#highFishpM = which(debFish[,10] > 150)
#debFish[highFishpM,c(1:3)]
#quantile(as.numeric(debFish[c(highFishpM), 5]))

#unique(class)
# select only fish or sharks with main non extreme metabolic rates
vectFish <- which(class == "Actinopterygii" & p.M > 0 & p.M < 100)
vectShark <- which(class == "Chondrichthyes" & p.M > 0 & p.M < 1000)

plot(log(zoom[vectFish]), log(p.M[vectFish]), xlab = "log structural length, cm", ylab = "log p.M", main = "Scaling of mass specific metabolic rate (DEB p.M.) to body size in fish")
abline(lm(log(p.M[vectFish]) ~ log(zoom[vectFish])), col = 'red')


plot(zoom[vectShark], p.M[vectShark], xlab = "zoom factor - sharks", ylab = "p.M")

#zoom factor is a structural length in cm, or a cubic root of structural volume in cm3. Let's assume it is a simple length in cm. Units of p.M is J cm-3 day-1.

metsizeFish = lm(log(p.M[vectFish]) ~ log(zoom[vectFish])) #do a linear regression of metabolic rate versus zoom factor 
summary(metsizeFish)
#coefficient of exp(3.43) or 30.1 and exponent of -0.31

#this means that Metrate = 30.1*Lmax^(-0.31)

metrate <- ((30.1*ModelSpecies$Lmax^(-0.31))/3000) #3000 is to convert Joules per day to g per day
metrateY <- metrate*365
#The average estimated value for the model species is ca 10 J cm3-1 day-1, or 0.003 g g-1 day-1, assuming 1g of structure mass equals 3000J and 1cm3 of wet weight is 1g. This would give ks = 1.1 g g-1 year-1. 
```

We cannot really use this value because this is a structural maintenance that scales as 1, whereas mizer assumes scaling exponent of 0.7 and it scales with the total body mass. To get from structure to total body mass we need to assume some level of reserve to structure ratio. However, the key point is that mass specific metabolic rate clearly decreases, not INCREASES with maximum body size. So overall we assume a scaling exponent of -0.25 and adjust the  If we take the total body maintenance, the unit value then should be lower, because reserves don't need structure. 


### Pred-prey interactions

Output values for beta, sigma, and resource availability

```{r}

tab4 <- mariaParams %>% select(species, beta, sigma, avail_PP, avail_BB, avail_AA)
#write.csv(tab4, file = "../suplTables/TableS4.csv")
knitr::kable(tab4, digits = 2)

write.csv(inter, file = "../suplTables/TableS5inter.csv")
knitr::kable(inter, digits = 2)

```

### Plankton spectrum: historical and projected

This is based on Julia's global runs. Need more explanation here, but I have time series. 

```{r}
lme_resource_ts <- readRDS("../inputs/lme_scale_gcm_inputs.rds")
#glimpse(lme_resource_ts)

sst <- lme_resource_ts %>% filter(variable == "sst") %>% filter (lme == 46)
area46 <- sst
area46$year <- as.numeric(substr(area46$month, 1,4))
area46$monthonly <- substr(area46$month, 6,7)

#Extreme future 
hist_rcp85 <- area46 %>% filter (scenario == "historical" | scenario == "rcp85")
#area46 <- as.data.frame(area46)

#get annual values 
annual_hist_rcp85 <- hist_rcp85 %>% group_by(year) %>% summarise (meanSST = mean(value))

#low emission scenario 
rcp45 <- area46 %>% filter (scenario == "rcp45")
#get annual values 
annual_rcp45 <- rcp45 %>% group_by(year) %>% summarise (meanSST = mean(value))

#plot lambda
plot(annual_hist_rcp85$year, (annual_hist_rcp85$meanSST - 273), pch = 19, xlab = "Year", ylab = "Projected SST in C")
points(annual_rcp45$year, (annual_rcp45$meanSST -273), col = 'orange', pch = 19)
abline (v= 2005, lty =2)

## projected temperature change by 2100 in high emission scenario
mean(annual_hist_rcp85$meanSST[which(annual_hist_rcp85$year > 2090)]) - 273
mean(annual_hist_rcp85$meanSST[which(annual_hist_rcp85$year == 2000)]) - 273

## projected temperature change by 2100 in high emission scenario
mean(annual_rcp45$meanSST[which(annual_rcp45$year > 2090)]) - 273



## get kappa and lambda values

lme_resource_ts <- readRDS("../inputs/lme_resource_ts.rds")

#Filter out only area 46 - SE AUstrlaian slope 
area46 <- lme_resource_ts %>% filter (lme == 46) 

#separate year and month, and be able to get annual mean slope values, since we don't model seasonal dynamics anyway
area46$year <- as.numeric(substr(area46$month, 1,4))
area46$monthonly <- substr(area46$month, 6,7)

#Extreme future 
hist_rcp85 <- area46 %>% filter (scenario == "historical" | scenario == "rcp85")
#area46 <- as.data.frame(area46)

#get annual values 
annual_hist_rcp85 <- hist_rcp85 %>% group_by(year) %>% summarise (meanLam = mean(lambda), meanKap = mean(kappa))

#low emission scenario 
rcp45 <- area46 %>% filter (scenario == "rcp45")
#get annual values 
annual_rcp45 <- rcp45 %>% group_by(year) %>% summarise (meanLam = mean(lambda), meanKap = mean(kappa))

#plot lambda
plot(annual_hist_rcp85$year, annual_hist_rcp85$meanLam, pch = 19, xlab = "Year", ylab = "Slope of the plankton spectrum")
points(annual_rcp45$year, annual_rcp45$meanLam, col = 'orange', pch = 19)
abline (v= 2005, lty =2)

#plot kappa
plot(annual_hist_rcp85$year, annual_hist_rcp85$meanKap, pch = 19, xlab = "Year", ylab = "Intercept of the plankton spectrum")
points(annual_rcp45$year, annual_rcp45$meanKap, col = 'orange', pch= 19)
abline (v= 2005, lty =2)

#Julia's kappa values are 0.03, which are presumably per m3. We 
0.03*100

```



### Benthos spectrum: data preparation

In this section I use data from very small benthic invertebrates collected by Kate Fraser (PhD student), and standardised per m2. For invertebrates bigger than 2g, data from RLS is used and compiled by Freddie Heather into weight bins on log2 scale. The data is combined, binned into equal weight bins on log10 scale and then a regression slope is fitted. 
From the first regression and by plotting abundances we can see that there is a big increase in abundance at largest weight groups, which is mostly due to urchins and partly lobsters. Given that urchins and lobsters are modelled explicitly we want to exclude them from teh background spectrum. Ideally this should be done by reanalysing Freddie's data without urchins and lobsters, but for now I just test a regression with a steeper sloe. Assuming a steeper slope and actually gives a better fit to small weight groups. We have to remember that Kate's data can underestimate the abundance (critters escape), but is less likely to overestimate it

```{r, eval = F}
Freddie <- read.csv(file = "../inputs/benthos/Freddie.csv") #data of large invertebrates
Kate <- read.csv(file = "../inputs/benthos/all_bysample_size.csv") #small invertebrates
KateCodes <- read.csv(file = "../inputs/benthos/sample_data_env_vectors.csv") #site codes for Kate's data

# coordinates for eastern Tasmanian coast
#TasmCoorLon <- c(146.5, 148.5) 
#TasmCoorLat <- c(-41.00, -43.60)
KateWgtGroups <- c(1.8E-06,4.8E-06, 1.1E-05, 2.9E-05, 7.1E-05, 1.8E-04, 4.5E-04, 1.1E-03, 2.8E-03, 6.8E-03, 1.7E-02, 4.2E-02, 1.1E-01, 2.5E-01, 6.8E-01, 1.6E+00) #weight groups used in Kate's data (size of sieves)

TasmCodes <- KateCodes %>% filter (lat > -43.60 & lat < -41.00) %>% filter (lon > 146.5 & lon < 148.5)
TasmCodes.l <- unique(TasmCodes$SampleCode)
TasmInvSmall <- Kate %>% filter (SampleCode %in% TasmCodes.l) 
TasmInvSmall <- TasmInvSmall[,-c(1:2)]

MeanAbund <- apply(TasmInvSmall, 2, mean)
MinAbund <- apply(TasmInvSmall, 2, min)
MaxAbund <- apply(TasmInvSmall, 2, max)

InvData <- list()
InvData$wgt <- KateWgtGroups
InvData$meanAb <- MeanAbund
InvData$minAb <- MinAbund
InvData$maxAb <- MaxAbund
InvData <- as.data.frame(InvData)
InvData <- InvData[-c(which(InvData$meanAb ==0)),] # remove size groups that have 0 abundance

#combine with Freddie's data about average abundance at size in Tasmania
InvData <- rbind(InvData, Freddie)
#save(InvData, file = "../inputs/benthos/BenticInvAbund_Tasm.RData")
```

###Benthos spectrum: derive the size slope

```{r}
load(file = "../inputs/benthos/BenticInvAbund_Tasm.RData")

#What is the mean abundance per m2 
sum(InvData$meanAb)

## now I have to bin data into bins of equal size on log10 scale 
InvData$cat <- NA
log10(min(InvData$wgt)) # minimum size on log10 scale
log10(max(InvData$wgt))

breaks <- seq(from = -6, to = 4) #make a vector of breaks on a log10 scale

#for each empirical weight put assign the bin on the log10 scale
for (i in 1:length(breaks)) {
  temp <- which((log10(InvData$wgt) > breaks[i]) & (log10(InvData$wgt) < breaks[i+1]))
  InvData$cat[c(temp)] <- i
}

#get abundances for the weight groups on the equal log10 scale (normalised)
InvDataBinned <- InvData %>% group_by(cat) %>% summarise (mean_ab = sum(meanAb), min_ab = sum(minAb), max_ab = sum(maxAb), meanWgt = mean(wgt))

#add the midpoint weight for each of the log10 weight groups 
InvDataBinned$wgtBinLog10 <- seq(from = -5.5, to = 3.5, by = 1) #mean weight in the bin on log 10 scale
InvDataBinned$wgtGroup <- 10^(InvDataBinned$wgtBinLog10)
InvDataBinned$bioPerm2 <- InvDataBinned$wgtGroup * InvDataBinned$mean_ab
#save(InvDataBinned, file = "../inputs/benthos/InvDataBinned.RData")

#Now we fit linear regression to the total abundance data 
bs <- lm(log10(InvDataBinned$mean_ab) ~ log10(InvDataBinned$wgtGroup))
summary(bs)

#Plot it 
plot(log10(InvDataBinned$wgtGroup), log10(InvDataBinned$mean_ab), type = 'l', ylim = c(-4, 6), main = "Benthos slopes in Tasmania: log10(Abund) = 1.1 - 0.62*log10(wgt_bin)", xlab = "Log10 (w,g)", ylab = "Log10 (Abundance: min, mean, max)")
points(log10(InvDataBinned$wgtGroup), log10(InvDataBinned$min_ab), type = 'l', lty = 2)
points(log10(InvDataBinned$wgtGroup), log10(InvDataBinned$max_ab), type = 'l', lty = 2)
abline(lm(log10(InvDataBinned$mean_ab) ~ log10(InvDataBinned$wgtGroup)), col = 'red')

plot(log10(InvDataBinned$wgtGroup), log10(InvDataBinned$mean_ab), type = 'l', lwd =4, ylim = c(-4, 6), xlab = "Log10 (w,g)", ylab = "Log10 (Abundance: min, mean, max)")
points(log10(InvDataBinned$wgtGroup), log10(InvDataBinned$min_ab), type = 'l', lty = 2,  lwd =2)
points(log10(InvDataBinned$wgtGroup), log10(InvDataBinned$max_ab), type = 'l', lty = 2, lwd = 2)
abline(lm(log10(InvDataBinned$mean_ab) ~ log10(InvDataBinned$wgtGroup)), lwd =3, col = 'orange')


## We can see that there is a big increase in abundance at largest weight groups, which is mostly due to urchins and partly lobsters. Given that urchins and lobsters are modelled explicitly we want to exclude them from teh background spectrum. Assuming a steeper slope and actually gives a better fit to small weight groups 
#AbNoUr <- 0.8 - 0.85*log10(InvDataBinned$wgtGroup)
## this equation is now used a very general approximation of the benthic slope
AbNoUr <- 0.8 - 0.9*log10(InvDataBinned$wgtGroup)

points(log10(InvDataBinned$wgtGroup), AbNoUr, col = 'blue', type = 'l', lwd =3)

abline(v = log10(0.7), lty = 3, lwd = 2)
abline(v = log10(2), lty = 3, lwd = 2) #this is where Freddie's data starts and Kate's data ends
abline(v = log10(5), lty = 2, lwd = 2)

#or if just plotting the original (nonbinned) weights 
plot(log10(InvData$wgt), log10(InvData$meanAb), type = 'l', ylim = c(-4, 6), main = "Benthos slopes in Tasmania: not normalised weight groups", xlab = "Log10 (w,g)", ylab = "Log10 (Abundance: min, mean, max)")
points(log10(InvData$wgt), log10(InvData$minAb), type = 'l', lty = 2)
points(log10(InvData$wgt), log10(InvData$maxAb), type = 'l', lty = 2)
abline(lm(log10(InvData$meanAb) ~ log10(InvData$wgt)), col = 'red')
points(log10(InvDataBinned$wgtGroup), AbNoUr, col = 'blue', type = 'l')
abline(v = log10(2), lty = 3)

```

### Fig1: map

```{r}
model_locs <- rls_bas %>% 
  filter (Location %in% LocationsWanted) %>%
  filter (SiteLat < -40.8) %>% 
  #filter (year < 2000) %>% 
  #filter (Method == 1) %>%
   group_by(SiteCode) %>% 
      summarise (latt = round(mean(SiteLat),3), long = round(mean(SiteLong),3), year = n_distinct(year), surveys = n_distinct(SurveyID)) 

theme_set(theme_bw())

world <- ne_countries(scale = "medium", returnclass = "sf")
#class(world)
#WHere are we centering? 
#center_tas <- c(-41.4545, 145.9707)

ggplot(data = world) +
  geom_sf(col="black", fill="lightgrey") +
  coord_sf(xlim = c(110, 160), ylim = c(-11, -45), expand = FALSE) + 
  geom_rect(mapping=aes(xmin=143, xmax=151, ymin=-39.5, ymax=-44.5), color="black", alpha=0) +
  theme_void()



ggplot(data = world) +
  geom_sf(col="black", fill="lightgrey") +
  coord_sf(xlim = c(143, 151), ylim = c(-39.5, -44.5), expand = FALSE) +
  #geom_point(aes(x = c(142, 144), y = c(-42, -41)), size = 1)
  geom_rect(mapping=aes(xmin=146.5, xmax=148.5, ymin=-41.2, ymax=-43.65, fill = "orange"), color="orange", alpha=0.0075) +
  geom_point(aes(x = model_locs$long, y = model_locs$latt), data = model_locs, size = (model_locs$surveys/100), colour = 'red') +
  geom_text(x=149.2, y=-41.7, label= "Bicheno", size = 4, fontface = 3) + 
  geom_text(x=149.4, y=-42.6, label= "Maria Island", size = 4, fontface = 3) + 
  geom_text(x=149.3, y=-43.4, label= "Ninepin & Tinderbox", size = 4, fontface = 3) + 
  theme_bw() +
  theme(
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text=element_text(size=10), 
    legend.position = "none"
  )

#+
#  theme_void()

###
geom_point(aes(x = rls_aus_geo$long, y = rls_aus_geo$latt), data = rls_aus_geo, size = (rls_aus_geo$species/30), color = rls_aus_geo$color)



## Now plot the geographic groups but the colour of the dot reflects the mean geosite temperature
rls_aus_geo$tempF <- floor(rls_aus_geo$anntemp) #round the annual SST to the nearest degree 
colvector <- list(NA)
colfunc <- colorRampPalette(c("yellow", "red")) #create colour ramp pallele
tempcol = colfunc(18) # sample 18 colours from it, as the difference between min and max geosite temperature is 18 degrees
colvector$col <- tempcol
colvector$tempF <- seq(from = 12, to = 29)
# add a temperature colour identifier to each geosite
rls_aus_geo$color <- colvector$col[match(rls_aus_geo$tempF, colvector$tempF)]

#load long term location coordinates
load(file = "inputs/longLoc.RData")




#Plot sites on a shapefile
rgdal::readOGR(dsn = ".", "aust_cd66states") %>% 
  fortify() %>% 
  ggplot() +
  geom_path(aes(x = long, y = lat, group = group), color = 'darkgrey', size = .3) +
  geom_point(aes(x = rls_aus_geo$long, y = rls_aus_geo$latt), data = rls_aus_geo, size = (rls_aus_geo$species/30), color = rls_aus_geo$color) + 
  geom_point(aes(x = longLoc$long, y = longLoc$lat), data = longLoc, shape = 8, size = 2, color = "black") +
  geom_text(x=111.5, y=-30, label= "Jurien Bay", size = 4, fontface = 3) + 
  geom_text(x=154, y=-35, label= "Jervis Bay", size = 4, fontface = 3) + 
  geom_text(x=144, y=-37, label= "Port Phillip Bay", size = 4, fontface = 3) + 
  geom_text(x=151, y=-39, label= "Bass Strait", size = 4, fontface = 3) + 
  geom_text(x=151, y=-41.5, label= "Bicheno", size = 4, fontface = 3) + 
  geom_text(x=152, y=-42.8, label= "Maria Island", size = 4, fontface = 3) + 
  geom_text(x=152.7, y=-44, label= "Ninepin & Tinderbox", size = 4, fontface = 3) + 
  geom_text(x=142.5, y=-43, label= "Port Davey", size = 4, fontface = 3) + 
  ggtitle("Mean annual SST of each geographic cell (12 to 29)") + 
  xlab("Longitutde") + ylab("Latitude")


```



